{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "mount_file_id": "1Hq-26b_GYMcyc4SDunFWs9CLIzj1Ye4L",
      "authorship_tag": "ABX9TyMUB7VRTV4a9gHqkX0wYBYq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yagoandres/dea_studies/blob/main/20250918_dea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.check_call(['pip', 'install', 'pulp'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
      ],
      "metadata": {
        "id": "L93PbqOouUYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pulp\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "ZjqySBZRuSs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The core DEA class, setting up and solving the linear programming\n",
        "# problems using PuLP.\n",
        "\n",
        "import pandas as pd\n",
        "import pulp\n",
        "\n",
        "\n",
        "class DEAProblem:\n",
        "\n",
        "    \"\"\"\n",
        "    A container for the elements of a data envelopment analysis problem. Sets\n",
        "    up the linear programmes and solves them with pulp.\n",
        "\n",
        "    Requires:\n",
        "\n",
        "        inputs: a pandas dataframe of the inputs to the DMUs\n",
        "        outputs: a pandas dataframe of the outputs from the DMUs\n",
        "        kind: 'VRS' or 'CRS'\n",
        "        in_weights: the weight restriction to apply to all inputs to all DMUs\n",
        "                    (default is [0, inf])\n",
        "        out_weights: the weight restriction to apply to all outputs to all DMUs\n",
        "                     (default is [0, inf)\n",
        "\n",
        "    Weight restrictions must be specified as a list. To specify only one bound\n",
        "    leave the other as None, eg. in_weights=[1, None].\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inputs, outputs, returns='CRS',\n",
        "                 in_weights=[0, None], out_weights=[0, None]):\n",
        "        \"\"\"\n",
        "        Set up the DMUs' problems, ready to solve.\n",
        "\n",
        "        \"\"\"\n",
        "        self.inputs = _to_dataframe(inputs)\n",
        "        self.outputs = _to_dataframe(outputs)\n",
        "        self.returns = returns\n",
        "\n",
        "        self.J, self.I = self.inputs.shape  # no of firms, inputs\n",
        "        _, self.R = self.outputs.shape  # no of outputs\n",
        "        self._i = range(self.I)  # inputs\n",
        "        self._r = range(self.R)  # outputs\n",
        "        self._j = range(self.J)  # DMUs\n",
        "\n",
        "        self._in_weights = in_weights  # input weight restrictions\n",
        "        self._out_weights = out_weights  # output weight restrictions\n",
        "\n",
        "        # creates dictionary of pulp.LpProblem objects for the DMUs\n",
        "        self.dmus = self._create_problems()\n",
        "\n",
        "    def _create_problems(self):\n",
        "        \"\"\"\n",
        "        Iterate over the inputs and create a dictionary of LP problems, one\n",
        "        for each DMU.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        dmu_dict = {}\n",
        "        for j0 in self._j:\n",
        "            dmu_dict[j0] = self._make_problem(j0)\n",
        "        return dmu_dict\n",
        "\n",
        "    def _make_problem(self, j0):\n",
        "        \"\"\"\n",
        "        Create a pulp.LpProblem for a DMU.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Set up pulp\n",
        "        prob = pulp.LpProblem(\"\".join([\"DMU_\", str(j0)]), pulp.LpMaximize)\n",
        "        self.inputWeights = pulp.LpVariable.dicts(\"inputWeight\", (self._j, self._i),\n",
        "                                                  lowBound=self._in_weights[0], upBound=self._in_weights[1])\n",
        "        self.outputWeights = pulp.LpVariable.dicts(\"outputWeight\", (self._j, self._r),\n",
        "                                                   lowBound=self._out_weights[0], upBound=self._out_weights[1])\n",
        "\n",
        "        # Set returns to scale\n",
        "        if self.returns == \"CRS\":\n",
        "            w = 0\n",
        "        elif self.returns == \"VRS\":\n",
        "            w = pulp.LpVariable.dicts(\"w\", (self._j, self._r))\n",
        "        else:\n",
        "            raise Exception(ValueError)\n",
        "\n",
        "        # Set up objective function\n",
        "        prob += pulp.LpAffineExpression(\n",
        "            [(self.outputWeights[j0][r1], self.outputs.values[j0][r1]) for r1 in self._r]) - w\n",
        "\n",
        "        # Set up constraints\n",
        "        prob += pulp.LpAffineExpression([(self.inputWeights[j0][i1],\n",
        "                                          self.inputs.values[j0][i1]) for i1 in self._i]) == 1, \"Norm_constraint\"\n",
        "        for j1 in self._j:\n",
        "            prob += self._dmu_constraint(j0, j1) - \\\n",
        "                w <= 0, \"\".join([\"DMU_constraint_\", str(j1)])\n",
        "        return prob\n",
        "\n",
        "    def _dmu_constraint(self, j0, j1):\n",
        "        \"\"\"\n",
        "        Calculate and return the DMU constraint for a single DMU's LP problem.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        eOut = pulp.LpAffineExpression(\n",
        "            [(self.outputWeights[j0][r1], self.outputs.values[j1][r1]) for r1 in self._r])\n",
        "        eIn = pulp.LpAffineExpression(\n",
        "            [(self.inputWeights[j0][i1], self.inputs.values[j1][i1]) for i1 in self._i])\n",
        "        return eOut - eIn\n",
        "\n",
        "    def _solver(self):\n",
        "        \"\"\"\n",
        "        Iterate over the dictionary of DMUs' problems, solve them, and collate\n",
        "        the results into a pandas dataframe.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        sol_status = {}\n",
        "        sol_weights = {}\n",
        "        sol_efficiency = {}\n",
        "\n",
        "        for ind, problem in list(self.dmus.items()):\n",
        "            problem.solve()\n",
        "            sol_status[ind] = pulp.LpStatus[problem.status]\n",
        "            sol_weights[ind] = {}\n",
        "            for v in problem.variables():\n",
        "                sol_weights[ind][v.name] = v.varValue\n",
        "            sol_efficiency[ind] = pulp.value(problem.objective)\n",
        "        return sol_status, sol_efficiency, sol_weights\n",
        "\n",
        "    def _build_weight_results_dict(self, sol_weights):\n",
        "        \"\"\"\n",
        "        Rename weights from input and output column names, then build a\n",
        "        pandas dataframe of all weights.\n",
        "\n",
        "        \"\"\"\n",
        "        import re\n",
        "        tmp_dict = {}\n",
        "        for dmu, d in list(sol_weights.items()):\n",
        "            tmp_dict[dmu] = {}\n",
        "            for key, _ in list(d.items()):\n",
        "                m = re.search(r'[0-9]+$',key)\n",
        "                i = int(m.group(0))\n",
        "                if key.startswith(\"input\"):\n",
        "                    tmp_dict[dmu][\"in_\" + str(self.inputs.columns[i])] = d[key]\n",
        "                if key.startswith(\"output\"):\n",
        "                    tmp_dict[dmu][\n",
        "                        \"out_\" + str(self.outputs.columns[i])] = d[key]\n",
        "        weight_results = pd.DataFrame.from_dict(tmp_dict).T\n",
        "\n",
        "        return weight_results\n",
        "\n",
        "    def solve(self, sol_type='technical'):\n",
        "        \"\"\"\"\n",
        "        Solve the problem and create attributes to hold the solutions.\n",
        "\n",
        "        Takes:\n",
        "            sol_type: 'technical'/'allocative'/'economic'\n",
        "            dmus: tuple defining range of DMUs to solve for.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if sol_type == 'technical':\n",
        "            sol_status, sol_efficiency, sol_weights = self._solver()\n",
        "            weight_results = self._build_weight_results_dict(sol_weights)\n",
        "            status_df = pd.Series(sol_status, name='Status')\n",
        "            status_df.index = self.inputs.index\n",
        "            efficiency_df = pd.Series(sol_efficiency, name='Efficiency')\n",
        "            efficiency_df.index = self.inputs.index\n",
        "\n",
        "            return DEAResults((('Status', status_df),\n",
        "                               ('Efficiency', efficiency_df),\n",
        "                               ('Weights', weight_results)))\n",
        "        else:\n",
        "            print(\"Solution type not yet implemented.\")\n",
        "            print(\"Solving for technical efficiency instead.\")\n",
        "            self.solve()\n",
        "\n",
        "\n",
        "class DEAResults(dict):\n",
        "\n",
        "    \"\"\"\n",
        "    A class to hold the results of a DEAProblem and provide methods for\n",
        "    their examination. Essentially a dictionary of pandas Series with\n",
        "    methods for conducting particular operations on DEA results.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "#    def __init__(self):\n",
        "#        super(DEAResults, self).__init__()\n",
        "#        pass\n",
        "\n",
        "    def find_comparators(self, dmu):\n",
        "        \"\"\"\n",
        "        Return the DMUs that form the frontier for the specified DMU.\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def env_corr(self, env_vars, qq_plot=False):\n",
        "        \"\"\"\n",
        "        Determine correlations with environmental/non-discretionary variables\n",
        "        using a logit regression. Tobit will be implemented when available\n",
        "        upstream in statsmodels.\n",
        "\n",
        "        Takes:\n",
        "            env_vars: A pandas dataframe of environmental variables\n",
        "\n",
        "        Returns:\n",
        "            corr_mod: the statsmodels' model instance containing the inputs\n",
        "                      and results from the logit model.\n",
        "\n",
        "        Note that there can be no spaces in the variables' names.\n",
        "        \"\"\"\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        from statsmodels.regression.linear_model import OLS\n",
        "        from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "        env_data = _to_dataframe(env_vars)\n",
        "        corr_data = env_data.join(self['Efficiency'])\n",
        "        corr_mod = OLS.from_formula(\n",
        "            \"Efficiency ~ \" + \" + \".join(env_vars.columns), corr_data)\n",
        "        corr_res = corr_mod.fit()\n",
        "\n",
        "        #plot qq of residuals\n",
        "        if qq_plot:\n",
        "            qqplot(corr_res.resid, line='s')\n",
        "            plt.title('Distribution of residuals')\n",
        "\n",
        "        print(corr_res.summary())\n",
        "\n",
        "        return corr_res\n",
        "\n",
        "\n",
        "def _to_dataframe(indata):\n",
        "    \"\"\"\n",
        "    Indexers require input to be a dataframe but the user may pass a\n",
        "    series. Check and cast series to dataframes.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if type(indata) == pd.core.frame.DataFrame:\n",
        "        return indata\n",
        "    elif type(indata) == pd.core.series.Series:\n",
        "        return pd.DataFrame(indata, columns=['input_data'])\n",
        "    else:\n",
        "        raise TypeError(\n",
        "            \"Input data is not a valid pandas DataFrame or Series.\")\n"
      ],
      "metadata": {
        "id": "b-22cFqr9tuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie_0HPLbhdxc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "pd.set_option('display.max_columns', 7)\n",
        "#%matplotlib inline\n",
        "file_path = \"/content/20250914_DEA_EnergySecurityPaper2.xls\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "  file_path = \"/content/drive/MyDrive/Colab Notebooks/20250914_DEA_EnergySecurityPaper2.xls\"\n",
        "\n",
        "\n",
        "i_installed_capacity_per_capita = pd.read_excel(file_path,sheet_name='I1-Installed Capacity Capita')\n",
        "i_energy_diversification        = pd.read_excel(file_path,sheet_name='I2-Energy diversification HHI')\n",
        "i_energy_import                 = pd.read_excel(file_path,sheet_name='I3-Energy import')\n",
        "i_perc_renewable                = pd.read_excel(file_path, sheet_name='I4-%Renewable')\n",
        "\n",
        "o_mwh_capita                    = pd.read_excel(file_path, sheet_name='O1-MWh capita')\n",
        "o_gdp_capita                    = pd.read_excel(file_path, sheet_name='O2-GDP_capita')\n",
        "o_electrification               = pd.read_excel(file_path, sheet_name='O3-Electrification')\n",
        "o_carbon_intensity              = pd.read_excel(file_path, sheet_name='O4-carbon intensity')\n",
        "\n",
        "range_countries = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
        "countries = i_installed_capacity_per_capita['(Capacity kW/person)'][range_countries]\n",
        "print (len(countries))\n",
        "print (countries)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir2write = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "os.mkdir(dir2write )"
      ],
      "metadata": {
        "id": "kuDcDwh-oBhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(data):\n",
        "    \"\"\"\n",
        "    Normalize data using robust scaling\n",
        "    \"\"\"\n",
        "    min_vals = np.min(data, axis=0)\n",
        "    max_vals = np.max(data, axis=0)\n",
        "    range_vals = max_vals - min_vals\n",
        "    print(range_vals)\n",
        "    if range_vals == 0:\n",
        "        print (\"ERROR range_vals=0\")\n",
        "    #range_vals[range_vals == 0] = 1\n",
        "\n",
        "    # Scale to [0.1, 1] range\n",
        "    normalized = 0.1 + 0.9 * (data - min_vals) / range_vals\n",
        "    return normalized"
      ],
      "metadata": {
        "id": "UxF1r63Lh_8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for year in range(2000, 2024):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # '2015', '2020', '2021']:\n",
        "  print(\"\\n\\n\\n\")\n",
        "  print (\"*********************************************\")\n",
        "  print (\"******* Processing year %s\" % year)\n",
        "  print (\"\\n\\n\\n\")\n",
        "\n",
        "  i_installed_capacity_per_capita_year    = normalize_data(pd.Series(list(i_installed_capacity_per_capita[year][range_countries]) , index=list(countries)))\n",
        "  i_energy_diversification_year           = normalize_data(pd.Series(list(1.0/i_energy_diversification[year][range_countries]), index=list(countries)))\n",
        "  i_energy_import_year                    = normalize_data(pd.Series(list(1.0/i_energy_import[year][range_countries]), index=list(countries)))\n",
        "  i_perc_renewable_year                   = normalize_data(pd.Series(list(i_perc_renewable[year][range_countries]), index=list(countries)))\n",
        "  #i_energy_input_year                     = pd.Series(list(i_energy_input[year][range_countries]), index=list(countries))\n",
        "\n",
        "  o_mwh_capita_year              = normalize_data(pd.Series(list(o_mwh_capita[year][range_countries]), index = list(countries)))\n",
        "  o_gdp_capita_year              = normalize_data(pd.Series(list(o_gdp_capita[year][range_countries]), index = list(countries)))\n",
        "  o_electrification_year         = normalize_data(pd.Series(list(o_electrification[year][range_countries]), index = list(countries)))\n",
        "  o_carbon_intensity_year        = normalize_data(pd.Series(list(1.0/o_carbon_intensity[year][range_countries]), index = list(countries)))\n",
        "\n",
        "\n",
        "\n",
        "  inputs_new = pd.DataFrame({'Installed Capacity per Capita': i_installed_capacity_per_capita_year,\n",
        "                                  'Energy Diversification': i_energy_diversification_year,\n",
        "                                  'Energy Import': i_energy_import_year,\n",
        "                                  'Percentage Renewable Energy': i_perc_renewable_year,\n",
        "                                  #'Energy Input': i_energy_input_year\n",
        "                                  })\n",
        "\n",
        "  outputs_new = pd.DataFrame({#'MWH per Capita': o_mwh_capita_year,\n",
        "                                   'GDP per Capita':o_gdp_capita_year,\n",
        "                                   #'Electrification': o_electrification_year,\n",
        "                                   'Carbon Intensity': o_carbon_intensity_year\n",
        "                                  })\n",
        "\n",
        "  print(\"------------\\n\\n)\")\n",
        "  print (\"Inputs New:\")\n",
        "  print(\"------------\\n\\n)\")\n",
        "  print (inputs_new)\n",
        "\n",
        "       #print (\"Inputs:\")\n",
        "       #print(\"------------\\n\\n)\")\n",
        "       #print (inputs)\n",
        "\n",
        "  print(\"------------\\n\\n)\")\n",
        "  print (\"Outputs New:\")\n",
        "  print(\"------------\\n\\n)\")\n",
        "  print (outputs_new)\n",
        "\n",
        "  prob = DEAProblem(inputs_new, outputs_new, returns='CRS')\n",
        "  myresults = prob.solve()\n",
        "\n",
        "  print ('----------------\\n\\n\\n')\n",
        "  print ('*** Status ***')\n",
        "  print ('----------------\\n\\n\\n')\n",
        "  print (myresults['Status'])\n",
        "\n",
        "  print ('----------------\\n\\n\\n')\n",
        "  print ('*** Efficiency ***')\n",
        "  print ('----------------\\n\\n\\n')\n",
        "\n",
        "  print (myresults['Efficiency'])\n",
        "\n",
        "  print ('----------------\\n\\n\\n')\n",
        "  print('*** Weights ***')\n",
        "  print('----------------\\n\\n\\n')\n",
        "\n",
        "  print (type(myresults['Weights']))\n",
        "  print (myresults['Weights'])\n",
        "\n",
        "  with pd.ExcelWriter(os.path.join(dir2write,\"dea_out_\"+ str(year)  + '.xlsx')) as writer:\n",
        "              inputs_new.to_excel(writer, sheet_name='Inputs')\n",
        "              outputs_new.to_excel(writer, sheet_name='Outputs')\n",
        "              myresults['Status'].to_excel(writer, sheet_name='Status')\n",
        "              myresults['Efficiency'].to_excel(writer, sheet_name='Efficiency')\n",
        "              myresults['Weights'].to_excel(writer, sheet_name='Weights')\n",
        "\n",
        "  if  os.path.exists(os.path.join(dir2write, \"dea_efficiency.xlsx\")):\n",
        "    with pd.ExcelWriter(os.path.join(dir2write, \"dea_efficiency.xlsx\"), mode='a') as writer2eff:\n",
        "                     myresults['Efficiency'].to_excel(writer2eff, sheet_name=str(year))\n",
        "  else:\n",
        "    with pd.ExcelWriter(os.path.join(dir2write, \"dea_efficiency.xlsx\"), mode='w') as writer2eff:\n",
        "                     myresults['Efficiency'].to_excel(writer2eff, sheet_name=str(year))\n",
        "\n",
        "  if os.path.exists(os.path.join(dir2write, \"dea_weights.xlsx\")):\n",
        "              with pd.ExcelWriter(os.path.join(dir2write, \"dea_weights.xlsx\"), mode='a') as writer2eff:\n",
        "                     myresults['Weights'].to_excel(writer2eff, sheet_name=str(year))\n",
        "  else:\n",
        "              with pd.ExcelWriter(os.path.join(dir2write, \"dea_weights.xlsx\"), mode='w') as writer2eff:\n",
        "                     myresults['Weights'].to_excel(writer2eff, sheet_name=str(year))\n",
        "\n",
        "  if os.path.exists(os.path.join(dir2write, \"dea_status.xlsx\")):\n",
        "              with pd.ExcelWriter(os.path.join(dir2write, \"dea_status.xlsx\"), mode='a') as writer2eff:\n",
        "                     myresults['Status'].to_excel(writer2eff, sheet_name=str(year))\n",
        "  else:\n",
        "              with pd.ExcelWriter(os.path.join(dir2write, \"dea_status.xlsx\"), mode='w') as writer2eff:\n",
        "                     myresults['Status'].to_excel(writer2eff, sheet_name=str(year))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4LCjh2Nv-IRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34mBIvR1p2G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s4T6XJ73p2T1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}